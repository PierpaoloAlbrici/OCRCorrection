{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to retrieve documents and texts for the analysis. \n",
    "There are a lot of different types of documents on the Vatican Website. I focus mainly on the following categories: \n",
    "\n",
    "1. Angelus\n",
    "2. Omelie\n",
    "\n",
    "In this work i want to cover the last 140 years circa, from Papa Leone XIII to Francesco. Obviuosly there isn't the same amount of document for each Pope, the most of the documents retrieved were written in recent times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pymongo\n",
    "import unicodedata\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"vatican\"]\n",
    "dataset = db['texts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we have to retrieve the list of the Holy Faters e their own urls to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] 200\n",
      "Leone XIII\n",
      "0 Angelus collected 0 Homilies collected\n",
      "\n",
      "Pio X\n",
      "0 Angelus collected 0 Homilies collected\n",
      "\n",
      "Benedetto XV\n",
      "0 Angelus collected 0 Homilies collected\n",
      "\n",
      "Pio XI\n",
      "0 Angelus collected 0 Homilies collected\n",
      "\n",
      "Pio XII\n",
      "0 Angelus collected 0 Homilies collected\n",
      "\n",
      "Giovanni XXIII\n",
      "[{}] /content/john-xxiii/it/homilies/1958/documents/hf_j-xxiii_hom_19581208_bergamo.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-ec34c68b4cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m                         \u001b[0mhomiliesPage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[{}]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhomiliesPage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'testo'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "#Pagina con la lista di tutti i papi\n",
    "req = urllib.request.urlopen('https://www.vatican.va/content/vatican/it/holy-father.index.html')\n",
    "print(\"[STATUS]\", req.getcode())\n",
    "holyFatherPage = BeautifulSoup(str(req.read()), 'html.parser')\n",
    "\n",
    "holyFatherTable = holyFatherPage.find(id='holy-father').find_all('a')\n",
    "docCounter = 0\n",
    "\n",
    "for i, a in enumerate(holyFatherTable):\n",
    "    if(i < 255):\n",
    "        continue\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    aCounter, hCounter = 0, 0\n",
    "        \n",
    "    #Pagina di sommario di ogni papa\n",
    "    page = BeautifulSoup(str(urllib.request.urlopen('https://www.vatican.va/'+a.get('href')).read()), 'html.parser')\n",
    "    site = page.find(\"a\", {'title': 'Sito Web'})\n",
    "    name = page.find(\"header\").find(\"h1\").get_text().replace('\\\\n', '').replace('\\\\t', '')\n",
    "    \n",
    "    if(not site): continue \n",
    "    print(name)\n",
    "    \n",
    "    #Sito web dei documenti di ogni papa\n",
    "    popePage = BeautifulSoup(str(urllib.request.urlopen(site.get('href')).read()), 'html.parser')\n",
    "    contentList = popePage.find(id = \"accordionmenu\")\n",
    "    \n",
    "    #Angelus - Regina Coeli\n",
    "    angelusIndex = (contentList.find(\"ul\", {'path': 'angelus'}))\n",
    "    if(angelusIndex):\n",
    "        #Trovo i link di ogni anno e li ciclo\n",
    "        angelusIndexList = angelusIndex.find_all('a')\n",
    "        for a in angelusIndexList:\n",
    "            url = a.get('href')\n",
    "            while(True):\n",
    "                req = urllib.request.urlopen('https://www.vatican.va'+url)\n",
    "                angelusIndexPage = BeautifulSoup(str(req.read()), 'html.parser')\n",
    "                \n",
    "                #Trovo i documenti\n",
    "                angelusDocList = angelusIndexPage.find('div', {'class': 'documento'}).find('ul').find_all('h1')\n",
    "                for b in angelusDocList: \n",
    "                    if(b.find('a')): \n",
    "                        time.sleep(3)\n",
    "                        \n",
    "                        req = urllib.request.urlopen('https://www.vatican.va'+(b.find('a').get('href')))\n",
    "                        angelusPage = BeautifulSoup(str(req.read()), 'html.parser')\n",
    "\n",
    "                        print(\"[\",req.getcode(),\"]\", b.find('a').get('href'))\n",
    "                        \n",
    "                        text = angelusPage.find('div', {'class': 'testo'})\\\n",
    "                            .find('div', {'class': 'text parbase container vaticanrichtext'})\\\n",
    "                            .get_text()\\\n",
    "                            .replace('\\\\n', '').replace('\\\\t', '').replace('\\\\r', '')\n",
    "                        \n",
    "                        item = {'author': name, 'type': 'Angelus', \n",
    "                                'url': b.find('a').get('href'), \n",
    "                                'text': unicodedata.normalize('NFKD', text)}\n",
    "                        \n",
    "                        dataset.insert_one(item)\n",
    "                        aCounter += 1\n",
    "                        \n",
    "                #Pagina successiva\n",
    "                nextPage = angelusIndexPage.find(\"nav\", {\"class\": \"navigation-pages\"})\n",
    "                if(nextPage):\n",
    "                    nextPage = nextPage.find(\"a\", {\"title\": \"Avanti\"})\n",
    "                    if(nextPage):\n",
    "                        url = nextPage.get('href')\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Omelie\n",
    "    homiliesIndex = (contentList.find(\"ul\", {'path': 'homilies'}))\n",
    "    if(homiliesIndex):\n",
    "        #Trovo i link di ogni anno e li ciclo\n",
    "        homiliesIndexList = homiliesIndex.find_all('a')\n",
    "        for a in homiliesIndexList:\n",
    "            url = a.get('href')\n",
    "            while(True):\n",
    "                req = urllib.request.urlopen('https://www.vatican.va'+url)\n",
    "                homiliesIndexPage = BeautifulSoup(str(req.read()), 'html.parser')\n",
    "                \n",
    "                #Trovo i documenti\n",
    "                homiliesDocList = homiliesIndexPage.find('div', {'class': 'documento'}).find('ul').find_all('h1')\n",
    "                for b in homiliesDocList: \n",
    "                    if(b.find('a')):\n",
    "                        time.sleep(3)\n",
    "                        \n",
    "                        req = urllib.request.urlopen('https://www.vatican.va'+(b.find('a').get('href')))\n",
    "                        homiliesPage = BeautifulSoup(str(req.read()), 'html.parser')\n",
    "\n",
    "                        print(\"[\",req.getcode(),\"]\", b.find('a').get('href'))                          \n",
    "                                                     \n",
    "                        text = homiliesPage.find('div', {'class': 'testo'})\\\n",
    "                            .find('div', {'class': 'text parbase container vaticanrichtext'})\\\n",
    "                            .get_text()\\\n",
    "                            .replace('\\\\n', '').replace('\\\\t', '').replace('\\\\r', '')\n",
    "                        \n",
    "                        item = {'author': name, 'type': 'Homilie', \n",
    "                                'url': b.find('a').get('href'), \n",
    "                                'text': unicodedata.normalize('NFKD', text)}\n",
    "                        \n",
    "                        dataset.insert_one(item)\n",
    "                        hCounter += 1\n",
    "                    \n",
    "                #Pagina successiva\n",
    "                nextPage = homiliesIndexPage.find(\"nav\", {\"class\": \"navigation-pages\"})\n",
    "                if(nextPage):\n",
    "                    nextPage = nextPage.find(\"a\", {\"title\": \"Avanti\"})\n",
    "                    if(nextPage): \n",
    "                        url = nextPage.get('href')\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "    print(aCounter, \"Angelus collected\", hCounter, \"Homilies collected\\n\")\n",
    "\n",
    "    docCounter =+ (aCounter + hCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-114-e6e2b92da74f>:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  dataset.count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
