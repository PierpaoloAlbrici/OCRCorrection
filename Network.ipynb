{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "db = client['vatican']\n",
    "dataset = db['wordsDataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    out = \"\"\n",
    "    for c in s.lower():\n",
    "        if c in CHAR_INDEX.keys():\n",
    "            out += c\n",
    "        else:\n",
    "            out += '#'\n",
    "    return \"\".join(out)\n",
    "\n",
    "def string_to_matrix(s, n=2):\n",
    "    z = preprocess(s)\n",
    "    C = np.zeros((len(CHAR_INDEX), len(CHAR_INDEX)))\n",
    "    for a, b in nltk.ngrams(z, n=n):\n",
    "        C[CHAR_INDEX[a], CHAR_INDEX[b]] += 1\n",
    "    C /= C.max()\n",
    "    return C\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = list(dataset.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wList = []\n",
    "\n",
    "for w in word: \n",
    "    if w['word'] not in wList: \n",
    "        wList.append(w['word'])\n",
    "    for o in w['occurrences']:\n",
    "        if o not in wList: \n",
    "            wList.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ''\n",
    "\n",
    "for w in wList: \n",
    "    for c in w: \n",
    "        if chars.count(c) == 0: \n",
    "            chars = chars+(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_INDEX = dict((c, i) for i, c in enumerate(chars))\n",
    "wordList = [x['word'] for x in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = [], []\n",
    "\n",
    "for w in word:\n",
    "    training_list, testing_list = [], []\n",
    "    \n",
    "    wrd = w['word']\n",
    "    for i, sw in enumerate(w['occurrences']):\n",
    "        if(wrd == sw): \n",
    "            training_list.append(sw)\n",
    "        else:\n",
    "            if(i <= 2):\n",
    "                training_list.append(sw)\n",
    "            else: \n",
    "                testing_list.append(sw)\n",
    "    \n",
    "    training_data.append((training_list, wrd))\n",
    "    testing_data.append((testing_list, wrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:  16414\n",
      "[(1, 13457), (2, 832), (3, 431)]\n",
      "TESTING DATA:  2562\n",
      "[(0, 14469), (1, 60), (2, 26), (3, 22), (4, 16), (5, 11), (6, 11), (7, 10), (8, 3), (9, 16), (10, 4), (11, 8), (12, 3), (13, 3), (14, 5), (15, 3), (18, 6), (19, 7), (20, 1), (25, 6), (26, 1), (30, 5), (34, 5), (35, 5), (45, 5), (47, 1), (51, 1), (54, 5), (59, 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('TRAINING DATA: ', sum([len(x[0]) for x in training_data]))\n",
    "\n",
    "training_stats = defaultdict(lambda: 0)\n",
    "\n",
    "for t in training_data: \n",
    "    training_stats[len(t[0])] += 1\n",
    "\n",
    "print(sorted(training_stats.items()))\n",
    "\n",
    "print('TESTING DATA: ', sum([len(x[0]) for x in testing_data]))\n",
    "\n",
    "testing_stats = defaultdict(lambda: 0)\n",
    "\n",
    "for t in testing_data:\n",
    "    testing_stats[len(t[0])] += 1\n",
    "\n",
    "print(sorted(testing_stats.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x212b1eb7c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = len(wordList)\n",
    "V = len(CHAR_INDEX) * len(CHAR_INDEX)\n",
    "LABEL_INDEX = dict((l, i) for i, l in enumerate(wordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2Gram(nn.Module):\n",
    "    def __init__(self, num_labels, size):\n",
    "        super(Simple2Gram, self).__init__()\n",
    "        self.linear = nn.Linear(size, num_labels)\n",
    "    \n",
    "    def forward(self, vec):\n",
    "        return F.log_softmax(self.linear(vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(s, n=2):\n",
    "    vec = torch.tensor(string_to_matrix(s, n=n)).float()\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def target(label):\n",
    "    return torch.LongTensor([LABEL_INDEX[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple2Gram(N_LABELS, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0207,  0.0224, -0.0063,  ..., -0.0177, -0.0194,  0.0227],\n",
      "        [ 0.0230,  0.0017,  0.0254,  ..., -0.0230,  0.0270,  0.0233],\n",
      "        [ 0.0168, -0.0027,  0.0096,  ..., -0.0033, -0.0224, -0.0217],\n",
      "        ...,\n",
      "        [-0.0019,  0.0177, -0.0243,  ...,  0.0079,  0.0207,  0.0134],\n",
      "        [-0.0095,  0.0049, -0.0020,  ...,  0.0074,  0.0213, -0.0092],\n",
      "        [-0.0021, -0.0089,  0.0027,  ..., -0.0056, -0.0214,  0.0031]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0047, -0.0245, -0.0240,  ...,  0.0182,  0.0130,  0.0003],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters(): \n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = training_data[0]\n",
    "    vec = vector(sample[0][0], n = 2)\n",
    "    log_probs = model(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14720])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-c78d0eb411ad>:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  C /= C.max()\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    for samples, label in training_data:\n",
    "        for instance in samples:\n",
    "            model.zero_grad()\n",
    "            vec = vector(instance)\n",
    "            tar = target(label)\n",
    "            log_probs = model(vec)\n",
    "            L = loss(log_probs, tar)\n",
    "            L.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for test, label in testing_data:\n",
    "        for word in test: \n",
    "            vec = vector(word, n=2)\n",
    "            log_probs = model(vec)\n",
    "            print('Input String', word)\n",
    "            prediction = np.argmax(log_probs.numpy())\n",
    "            print('Guess:', wordList[prediction], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ts = time.time()\n",
    "\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
