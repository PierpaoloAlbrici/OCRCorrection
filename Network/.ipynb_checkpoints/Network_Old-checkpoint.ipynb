{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "db = client['vatican']\n",
    "dataset = db['wordsDataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    out = \"\"\n",
    "    for c in s.lower():\n",
    "        if c in CHAR_INDEX.keys():\n",
    "            out += c\n",
    "        else:\n",
    "            out += '#'\n",
    "            \n",
    "    if(len(s) == 1):\n",
    "        return '#'\n",
    "    \n",
    "    return \"\".join(out)\n",
    "\n",
    "def string_to_matrix(s, n=2):\n",
    "    z = preprocess(s)\n",
    "    C = np.zeros((len(CHAR_INDEX), len(CHAR_INDEX)))\n",
    "    for a, b in nltk.ngrams(z, n=n):\n",
    "        C[CHAR_INDEX[a], CHAR_INDEX[b]] += 1\n",
    "        \n",
    "    #print(C, C.max())\n",
    "    #Add one to avoid division by zero\n",
    "    C /= C.max()\n",
    "    \n",
    "    return C\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piera\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(dataset.count())\n",
    "word = list(dataset.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4759e409114b35b39af6c29909c62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wList = []\n",
    "wCorrectList = []\n",
    "for w in tqdm(word): \n",
    "    if w['word'] not in wList: \n",
    "        wList.append(w['word'])\n",
    "    if w['word'] not in wCorrectList:\n",
    "        wCorrectList.append(w['word'])\n",
    "    for o in w['occurrences']:\n",
    "        if o not in wList: \n",
    "            wList.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5123\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(wCorrectList):\n",
    "    if w == '19##':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14421\n",
      "16917\n"
     ]
    }
   ],
   "source": [
    "print(len(wCorrectList))\n",
    "print(len(wList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ''\n",
    "\n",
    "for w in wList: \n",
    "    for c in w: \n",
    "        if chars.count(c) == 0: \n",
    "            chars = chars+(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "CHAR_INDEX = dict((c, i) for i, c in enumerate(chars))\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = [], []\n",
    "\n",
    "for w in word:\n",
    "    training_list, testing_list = [], []\n",
    "    \n",
    "    wrd = w['word']\n",
    "    for i, sw in enumerate(w['occurrences']):\n",
    "        if(wrd != sw): \n",
    "            if(i < 5):\n",
    "                training_list.append(sw)\n",
    "            else: \n",
    "                testing_list.append(sw)\n",
    "\n",
    "    training_data.append((training_list, wrd))\n",
    "    testing_data.append((testing_list, wrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:  1958\n",
      "[(0, 13246), (1, 988), (2, 150), (3, 62), (4, 121)]\n",
      "TESTING DATA:  660\n",
      "[(0, 14480), (1, 23), (2, 11), (3, 7), (4, 3), (5, 7), (6, 5), (7, 2), (8, 5), (9, 1), (10, 6), (11, 1), (12, 3), (13, 1), (14, 1), (15, 1), (17, 1), (18, 2), (24, 1), (29, 1), (31, 1), (33, 1), (38, 1), (39, 1), (58, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('TRAINING DATA: ', sum([len(x[0]) for x in training_data]))\n",
    "\n",
    "training_stats = defaultdict(lambda: 0)\n",
    "\n",
    "for t in training_data: \n",
    "    training_stats[len(t[0])] += 1\n",
    "\n",
    "print(sorted(training_stats.items()))\n",
    "\n",
    "print('TESTING DATA: ', sum([len(x[0]) for x in testing_data]))\n",
    "\n",
    "testing_stats = defaultdict(lambda: 0)\n",
    "\n",
    "for t in testing_data:\n",
    "    testing_stats[len(t[0])] += 1\n",
    "\n",
    "print(sorted(testing_stats.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f6b93ee330>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = len(wCorrectList)\n",
    "V = len(CHAR_INDEX) * len(CHAR_INDEX)\n",
    "LABEL_INDEX = dict((l, i) for i, l in enumerate(wCorrectList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2Gram(nn.Module):\n",
    "    def __init__(self, num_labels, size):\n",
    "        super(Simple2Gram, self).__init__()\n",
    "        self.linear = nn.Linear(size, num_labels)\n",
    "    \n",
    "    def forward(self, vec):\n",
    "        return F.log_softmax(self.linear(vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(s, n=2):\n",
    "    vec = torch.tensor(string_to_matrix(s, n=n)).float()\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def target(label):\n",
    "    return torch.LongTensor([LABEL_INDEX[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple2Gram(N_LABELS, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0218,  0.0237, -0.0067,  ...,  0.0085, -0.0187,  0.0139],\n",
      "        [-0.0244,  0.0246,  0.0277,  ...,  0.0193, -0.0028, -0.0009],\n",
      "        [-0.0021,  0.0238,  0.0162,  ...,  0.0167, -0.0174,  0.0055],\n",
      "        ...,\n",
      "        [ 0.0019,  0.0080,  0.0123,  ..., -0.0073,  0.0179, -0.0049],\n",
      "        [-0.0005,  0.0274, -0.0130,  ...,  0.0191,  0.0160, -0.0109],\n",
      "        [-0.0168,  0.0069, -0.0015,  ..., -0.0236,  0.0073,  0.0199]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0143, -0.0196,  0.0257,  ...,  0.0125,  0.0049,  0.0142],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters(): \n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = training_data[0]\n",
    "    vec = vector(sample[0][0], n = 2)\n",
    "    log_probs = model(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14421])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cc6062ea8c4e73927941893a073254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f00afd9dc94dd7a3a3562b5ae704b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1)): #50\n",
    "    for samples, label in tqdm(training_data):\n",
    "        for instance in samples:\n",
    "            #print(instance, samples, label)\n",
    "            model.zero_grad()\n",
    "            vec = vector(instance)\n",
    "            tar = target(label)\n",
    "            log_probs = model(vec)\n",
    "            #print(log_probs)\n",
    "            L = loss(log_probs, tar)\n",
    "            L.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-37-7b1f200823e6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-7b1f200823e6>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    torch.save(model.state_dict(), 'C:\\Users\\piera\\Desktop\\Repository\\VaticanGenderEvolution\\models')\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "#PATH = \"C:\\Users\\piera\\Desktop\\Repository\\VaticanGenderEvolution\\models\"\n",
    "#PATH = \"C:\\Users\\piera\\Desktop\"\n",
    "torch.save(model.state_dict(), '.\\models\\model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.distributions import Categorical \n",
    "\n",
    "predictions, y_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test, label in testing_data:\n",
    "        for word in test: \n",
    "            vec = vector(word, n=2)\n",
    "            log_probs = model(vec)\n",
    "            print('Input String', word)\n",
    "            prediction = np.argmax(log_probs.numpy())\n",
    "            print('Guess:', wCorrectList[prediction], '(',label ,')' '\\n')\n",
    "            \n",
    "            predictions.append(model(vec))\n",
    "            y_true.append(label)\n",
    "\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy = lambda x: Categorical(probs = x).entropy()\n",
    "#E = sum([entropy(p) for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [wCorrectList[np.argmax(p.numpy())] for p in predictions]\n",
    "#y_pred = [np.argmax(p.numpy()) for p in predictions]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lst = []\n",
    "for i in y_true:\n",
    "    lst.append(type(i))\n",
    "print(set(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multilabel_confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
